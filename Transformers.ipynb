{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5sksjStKBNWByRZbMlBMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashishV999/nlp-transformers-journey/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - Natural language Processing\n",
        "understand human lang, not just single words but **CONTEXT**\n",
        "\n",
        "#NLP common tasks Ex\n",
        "- classify\n",
        "- generate new sentence from input\n",
        "- multimodality (speech , image)\n",
        "\n",
        "\n",
        "# LLM - large lang models\n",
        "- **massive** amount of data train\n",
        "- perform **general** nlp tasks without task specific training\n",
        "\n",
        "\n",
        "# Difference in performance if i use task-specific train model vs LLM ?\n",
        "- In my chatbot I was using **open ai chat completion feature**\n",
        "which uses gpt [LLM]  -> general nlp tasks -> cause its been trained so billions of datasets -> most likly its gonna give me right answer casue of its heavy training\n",
        "\n",
        "  - BUTTTTT its gonna be so expensive cause imma pay cost per API call  \n",
        "  - SPEED - SLOW - call api every time\n",
        "  - less accurate in giving me domain specific correct answers\n",
        "\n",
        "\n",
        "- Better way:\n",
        "\n",
        "We will **finetune a pretrained NLP model** (like BERT, distilbert) on a speciifc task using labeled dataset\n",
        "\n",
        "- FAST & cheap - use computer resources rather than any api and smaller model with less parameters and run locally\n",
        "\n",
        "- more accurate as it has domain specific data\n",
        "\n",
        "BUT WE NEED DATA TO TRAIN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_QF9YND8XgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRANSFORMERS LIBRARY\n",
        "Now to work with pretrained models on hugging face for NLP tasks , I'm gonna use transformers library esp **pipeline function** ,\n",
        "- Fast quick way to work with models as it handles PRE or POST processing\n",
        "- DO NOT USE WHEN WANT LOW-LEVEL FULL CONTROL\n",
        "\n",
        "## PIPELINE FOR MULTIMODALITY\n",
        "\n",
        "### TEXT - Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "jSvHhkS2hjnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "K2TysfThj4FO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline by itself cache model according to its task\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2I6DdG5tl7Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"I am so excited to got to karan aujla's concert\",\n",
        "    \"I was unable to get tickets for the concert\"\n",
        "]\n",
        "\n",
        "result = classifier(sentences)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiUSMSNZmONA",
        "outputId": "5a2322a4-3d11-46bc-c5f7-b6bfadb41fcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997145533561707},\n",
              " {'label': 'NEGATIVE', 'score': 0.9997726082801819}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEXT GENERATION"
      ],
      "metadata": {
        "id": "2J_FCxJh8fN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "EKAYITReA6Sz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator= pipeline(\"text-generation\", model=\"distilgpt2\")"
      ],
      "metadata": {
        "id": "haQqS25FBy2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"This year, I will work to improve\", max_new_tokens=200)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNTDiPZnEnV9",
        "outputId": "fa850ae5-8c11-41d3-ccd8-286fa322f950"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"This year, I will work to improve my game and help bring back more than 1,500 players. I believe this will be the year I am the champion of Team Dignitas. I hope you all have great memories.\\n\\n\\nI'm not a fan of Team Dignitas, but I've been in the LCS all season long and I hope that you all will soon find some great memories. I'm looking forward to seeing you all again.\\nThank you very much for listening.\\n-\\nTia\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu55TEYKG6DSUXxG7lDeKp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashishV999/nlp-transformers-journey/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - Natural language Processing\n",
        "understand human lang, not just single words but **CONTEXT**\n",
        "\n",
        "#NLP common tasks Ex\n",
        "- classify\n",
        "- generate new sentence from input\n",
        "- multimodality (speech , image)\n",
        "\n",
        "\n",
        "# LLM - large lang models\n",
        "- **massive** amount of data train\n",
        "- perform **general** nlp tasks without task specific training\n",
        "\n",
        "\n",
        "# Difference in performance if i use task-specific train model vs LLM ?\n",
        "- In my chatbot I was using **open ai chat completion feature**\n",
        "which uses gpt [LLM]  -> general nlp tasks -> cause its been trained so billions of datasets -> most likly its gonna give me right answer casue of its heavy training\n",
        "\n",
        "  - BUTTTTT its gonna be so expensive cause imma pay cost per API call  \n",
        "  - SPEED - SLOW - call api every time\n",
        "  - less accurate in giving me domain specific correct answers\n",
        "\n",
        "\n",
        "- Better way:\n",
        "\n",
        "We will **finetune a pretrained NLP model** (like BERT, distilbert) on a speciifc task using labeled dataset\n",
        "\n",
        "- FAST & cheap - use computer resources rather than any api and smaller model with less parameters and run locally\n",
        "\n",
        "- more accurate as it has domain specific data\n",
        "\n",
        "BUT WE NEED DATA TO TRAIN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_QF9YND8XgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRANSFORMERS LIBRARY\n",
        "Now to work with pretrained models on hugging face for NLP tasks , I'm gonna use transformers library esp **pipeline function** ,\n",
        "- Fast quick way to work as it handles PRE or POST processing\n",
        "- DO NOT USE WHEN WANT LOW-LEVEL FULL CONTROL\n",
        "\n",
        "## PIPELINE FOR MULTIMODALITY\n",
        "\n",
        "### TEXT\n",
        "Here I will classify text and i will provide my own labels instead of depending on labels of models , so its called zero shot classification\n",
        "\n"
      ],
      "metadata": {
        "id": "jSvHhkS2hjnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "K2TysfThj4FO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline by itself cache model according to its task\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2I6DdG5tl7Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"I am so excited to got to karan aujla's concert\",\n",
        "    \"I was unable to get tickets for the concert\"\n",
        "]\n",
        "\n",
        "result = classifier(sentences)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiUSMSNZmONA",
        "outputId": "5a2322a4-3d11-46bc-c5f7-b6bfadb41fcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997145533561707},\n",
              " {'label': 'NEGATIVE', 'score': 0.9997726082801819}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}
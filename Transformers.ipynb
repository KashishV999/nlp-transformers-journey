{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqx0Sol3ACsI0Krl7srBu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashishV999/nlp-transformers-journey/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - Natural language Processing\n",
        "understand human lang, not just single words but **CONTEXT**\n",
        "\n",
        "#NLP common tasks Ex\n",
        "- classify\n",
        "- generate new sentence from input\n",
        "- multimodality (speech , image)\n",
        "\n",
        "\n",
        "# LLM - large lang models\n",
        "- **massive** amount of data train\n",
        "- perform **general** nlp tasks without task specific training\n",
        "\n",
        "\n",
        "# Difference in performance if i use task-specific train model vs LLM ?\n",
        "- In my chatbot I was using **open ai chat completion feature**\n",
        "which uses gpt [LLM]  -> general nlp tasks -> cause its been trained so billions of datasets -> most likly its gonna give me right answer casue of its heavy training\n",
        "\n",
        "  - BUTTTTT its gonna be so expensive cause imma pay cost per API call  \n",
        "  - SPEED - SLOW - call api every time\n",
        "  - less accurate in giving me domain specific correct answers\n",
        "\n",
        "\n",
        "- Better way:\n",
        "\n",
        "We will **finetune a pretrained NLP model** (like BERT, distilbert) on a speciifc task using labeled dataset\n",
        "\n",
        "- FAST & cheap - use computer resources rather than any api and smaller model with less parameters and run locally\n",
        "\n",
        "- more accurate as it has domain specific data\n",
        "\n",
        "BUT WE NEED DATA TO TRAIN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_QF9YND8XgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRANSFORMERS LIBRARY\n",
        "Now to work with pretrained models on hugging face for NLP tasks , I'm gonna use transformers library esp **pipeline function** ,\n",
        "- Fast quick way to work with models as it handles PRE or POST processing\n",
        "- DO NOT USE WHEN WANT LOW-LEVEL FULL CONTROL\n",
        "\n",
        "## PIPELINE FOR MULTIMODALITY\n",
        "\n",
        "### TEXT - Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "jSvHhkS2hjnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "K2TysfThj4FO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline by itself cache model according to its task\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2I6DdG5tl7Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"I am so excited to got to karan aujla's concert\",\n",
        "    \"I was unable to get tickets for the concert\"\n",
        "]\n",
        "\n",
        "result = classifier(sentences)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiUSMSNZmONA",
        "outputId": "5a2322a4-3d11-46bc-c5f7-b6bfadb41fcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997145533561707},\n",
              " {'label': 'NEGATIVE', 'score': 0.9997726082801819}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEXT GENERATION"
      ],
      "metadata": {
        "id": "2J_FCxJh8fN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "EKAYITReA6Sz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator= pipeline(\"text-generation\", model=\"distilgpt2\")"
      ],
      "metadata": {
        "id": "haQqS25FBy2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output= generator(\"This year, I will work to improve\", max_new_tokens=200)\n",
        "\n"
      ],
      "metadata": {
        "id": "hNTDiPZnEnV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lgDqpgQHuux",
        "outputId": "52802b5e-e203-476b-9e91-f8248563b916"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"This year, I will work to improve our relationship with China, and I hope that this will be a positive development for our bilateral relations. It is a good time to reflect on the progress we have made in the past two years.\\n\\n\\n\\nAs a result, I will be working for China, and I hope that this will be a positive development for our bilateral relations. It is a good time to reflect on the progress we have made in the past two years.\\nWe are also looking for the Chinese investors to invest in the Chinese government. China is the second largest investor in China, and the second largest investor in China, according to the latest figures released by the People's Bank.\\nChina's government is also investing heavily in the Chinese government. After a great deal of growth, there are also potential opportunities to invest in China.\\nChina's government is also investing heavily in the Chinese government. After a great deal of growth, there are also potential opportunities to invest in China.\\nChina is the second largest investor\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MASK FILLING"
      ],
      "metadata": {
        "id": "gTjsHpk6V-bT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "mtQofcvBWELz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')"
      ],
      "metadata": {
        "id": "jW_Nze0OZWaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"I want to eat spicy dish called [MASK] today\", top_k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5_rHD_KZZeV",
        "outputId": "7d47c078-c536-4e92-ea79-6cfe1e4ef535"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.08729230612516403,\n",
              "  'token': 7975,\n",
              "  'token_str': 'chicken',\n",
              "  'sequence': 'i want to eat spicy dish called chicken today'},\n",
              " {'score': 0.0335581935942173,\n",
              "  'token': 2833,\n",
              "  'token_str': 'food',\n",
              "  'sequence': 'i want to eat spicy dish called food today'},\n",
              " {'score': 0.01735408790409565,\n",
              "  'token': 27130,\n",
              "  'token_str': 'noodles',\n",
              "  'sequence': 'i want to eat spicy dish called noodles today'}]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION ANSWERING"
      ],
      "metadata": {
        "id": "ZSxYNXlGbRFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n"
      ],
      "metadata": {
        "id": "e7Khcspgbdlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(\n",
        "    question=\"what did i ate today?\",\n",
        "    context=\"I went with my friend to cinema and while coming back\"\n",
        "    \"we stopped at some place and the we were feeling hungry so we had butter chicken but\"\n",
        "    \"then we drove to a mall to do some shopping where we did not like anything\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfaLJgSmcHA6",
        "outputId": "92dbc09b-c929-4b75-cfff-69d10713a3b4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.8882359862327576,\n",
              " 'start': 119,\n",
              " 'end': 133,\n",
              " 'answer': 'butter chicken'}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMAGE"
      ],
      "metadata": {
        "id": "OagEPcswclHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "image_classifier = pipeline(\n",
        "    task=\"image-classification\", model=\"google/vit-base-patch16-224\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "MaJnP-4AcnAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = image_classifier(\n",
        "    \"https://images.unsplash.com/photo-1716467891152-1b43a96de578?fm=jpg&q=60&w=3000&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8NHx8bWFsZSUyMGNhdHxlbnwwfHwwfHx8MA%3D%3D\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkhOqAvSc6oj",
        "outputId": "43daa8a5-d508-476b-d346-637ce6c97b16"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'Egyptian cat', 'score': 0.5328313112258911}, {'label': 'tiger cat', 'score': 0.29956790804862976}, {'label': 'tabby, tabby cat', 'score': 0.08417428284883499}, {'label': 'lynx, catamount', 'score': 0.005267893895506859}, {'label': 'Siamese cat, Siamese', 'score': 0.005000841338187456}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AUDIO  (Note: its exactly SAMEEEE , use this whisper for next project)"
      ],
      "metadata": {
        "id": "Eu2R0qwEFSEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "transcriber = pipeline(\n",
        "    task=\"automatic-speech-recognition\", model=\"openai/whisper-small\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "5iAqNd_OFPNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = transcriber(\n",
        "\"https://cdn-media.huggingface.co/speech_samples/sample1.flac\")\n"
      ],
      "metadata": {
        "id": "E-vYpMD3FP5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-cXZ9jeL-Nt",
        "outputId": "1bdc6546-0b3b-485a-bb29-d8cb945be688"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \" going along slushy country roads and speaking to damp audiences in drafty school rooms day after day for a fortnight. He'll have to put in an appearance at some place of worship on Sunday morning, and he can come to us immediately afterwards.\"}\n"
          ]
        }
      ]
    }
  ]
}